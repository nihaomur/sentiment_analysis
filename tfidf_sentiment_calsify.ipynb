{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lqllLKnFUUL"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWqiopDIFUUQ"
      },
      "source": [
        "# Training a regression model for document classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4qu0dn5BX22T"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/01NLP/data/movie_data.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0K7jmmA_tV8",
        "outputId": "740b1923-8dda-4603-c6ec-ce6a4fced14e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tBmK9FtxX2zF"
      },
      "outputs": [],
      "source": [
        "df = df[0:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DV7EIs5vX2ry"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text) # re.sub 取代\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # :-) ;-( =-D :-P :D :-(\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31HplHS_X2nq"
      },
      "outputs": [],
      "source": [
        "df['review'] = df['review'].map(preprocessor) # or apply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzzWgXiKX2kO",
        "outputId": "f9c35e80-47ca-4a62-960c-634278573036"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kPZjepYXX2da"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "# TfidfVectorizer 內設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cun2wY32X2g0"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "# TfidfVectorizer 內設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EQ7qXaTgntw",
        "outputId": "c059e317-5f05-48b4-9b07-d7d75b8ee858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN size: 9000\n",
            "TEST size: 1000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=1, stratify=df['sentiment'])\n",
        "print(\"TRAIN size:\", len(df_train))\n",
        "print(\"TEST size:\", len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "G9dgx3MUX2T7"
      },
      "outputs": [],
      "source": [
        "X_train = df_train['review'].values # values 轉 array\n",
        "y_train = df_train['sentiment'].values\n",
        "X_test = df_test['review'].values\n",
        "y_test = df_test['sentiment'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "0kwyuoirH2ah",
        "outputId": "7806feeb-9766-4c3c-e2b0-bb0223751f2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in the previews the 40 year old virgin boasts the image of another immature sex romp about a 40 ish lonely guy who suddenly feels the urge to do the deed simply because he hasn t too many past bad experiences have dampened his enthusiasm to the point that he avoids women completely and then the unexpected happens he falls in love what s more there s a movie out about it and it s called the 40 year old virgin the virgin of the title is andy stitzer steve carell who is indeed 40 works as an employee at an electronics store and collects vintage action figures which are displayed all throughout his nice bachelor pad for all to see he has a lovely home theater system and watches survivor with his two kind elderly neighbors he s a pretty picturesque definition of the lonely guy who needs to go out more and talk to more women now here s the real novelty with this picture it does the impossible task of actually dealing with its subject matter in a cute mature fashion this is a movie that could very easily have turned out a lot differently in the hands of a more transparent team of filmmakers it could have descended into endless sex gags and jokes but thankfully this picture never stoops that low sure there are sex jokes here and there and even a few prods are aimed at the gay community which are in no way meant to be taken as gay bashing as two of the characters exchange insults towards each other while playing a video game mortal kombat deception no less the ultimate testosterone driven fightfest for guys as someone who is rapidly approaching 20 collects mcfarlane toys action figures and has himself never done the deed i found this film amusing and touching in a way that a similar themed movie could never have been i was able to relate to the character of andy stitzer more than anyone in the theater because i was the only teenager present at this showing everyone else looked like they were all past 40 a bit arrogant i know but would you you is italicized still be able to relate if you were the only teen present at an afternoon screening of the 40 year old virgin of course andy has never had sex and wakes up everyday with morning rise don t ask and he s pressured by his buddies to try outlandish methods of gaining the attention of the opposite sex when it s first discovered andy is a virgin at 40 his three buddies and fellow electronics store coworkers david paul rudd jay romany malco and cal seth rogen all at first assume he s gay because he s never been with a woman which couldn t be any further from the truth the truth is andy loves women but past traumatic experiences revealed hilariously one after the other in a flashback sequence have put him on the sidelines for good david jay and cal each embark on a mission to get andy laid so help them all but you know that such escapades will only end in disaster as proved by one date with nicky leslie mann who puts andy through the worst drunk driving experience i think anyone would not want to go through and he has a rather creepy encounter with beth elizabeth banks the pretty girl who works in the bookstore and is eventually revealed to be a total sex fiend things brighten up for andy when he meets trish catherine keener the friendly woman who works at a store across the street that sells stuff on ebay for people hmmm and with that nice looking collection of action figures you can go figure that in the end a large financial payoff awaits him that is if he can ever do the deed at last this is the sex romp we ve been waiting for it deals with a very real issue a lot of lonely guys probably go through not that anything is wrong with being a virgin but let s look at the big picture how many of us lonely guys want to be a lonely guy forever the important thing we re taught in this picture is that lonely guy must be himself i don t think he needs to go through body waxing like andy does which is side splitting to be honest and according to this website and various other news articles was in fact real and so was the blood on carell s shirt afterward the 40 year old virgin was directed by judd apatow and co written by himself and carell which originated as a skit that starred carell carell is sweet and human as his character is not some layabout who approaches this thing with his eyes shut this is probably one of the most intelligent romps i ve ever seen and is not offensive a whole lot because its characters are treated with dignity and respect even carell s buddies who pass off bad advice to cover up their own relationship insecurities can be related to on a fundamental level the way the 40 year old virgin plays out is indeed funny in the end but i ll leave that up to you the viewer to observe surely if anyone can go through the things andy does and still have the strength to attract a woman as sexy as catherine keener then it s true it is never too late 10 10'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My1VVKkLbLK_",
        "outputId": "4e68e64a-b323-4a2d-8bd9-2891d3d307cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', \"it'\", 'onc', 'onli', 'ourselv', \"she'\", \"should'v\", 'themselv', 'thi', 'veri', 'wa', 'whi', \"you'r\", \"you'v\", 'yourselv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # not TfidfTransformer which uses TF from CountVectorizer as input\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop, tokenizer=tokenizer_porter)\n",
        "X_train = tfidf.fit_transform(X_train).toarray() # X_train: array\n",
        "# tfidf: 文字 轉 數字特徵向量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS0sdr0EboF9",
        "outputId": "9fd0737d-1331-4027-b772-0744726e343b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9000, 35042)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DQzQwcXee7hK"
      },
      "outputs": [],
      "source": [
        "X_test = tfidf.transform(X_test).toarray() # X_test: array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIk9MvCfe-mx",
        "outputId": "4830cab1-f97a-4fd2-ff50-04584d408e0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 35042)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XniiHk81JJRI",
        "outputId": "33511abc-bea8-4545-d7d5-623476a8bf29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LNPTXbo3-AN"
      },
      "outputs": [],
      "source": [
        "# logistic regression: classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "5tMmusUtbVs6",
        "outputId": "dba91505-8c89-4f1b-9914-7b2024541b0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mWWAB1hbVpx",
        "outputId": "2b5ae242-7e28-41c2-8ccc-3713fff89f1a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.87"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr.score(X_test, y_test) #accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GfYD7f73phy"
      },
      "outputs": [],
      "source": [
        "# nn model dense layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2qKbjqbbLHg",
        "outputId": "41b79e7c-1fea-4bbc-e30a-d0968a8ed074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                560688    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 560833 (2.14 MB)\n",
            "Trainable params: 560833 (2.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(8, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # 輸出:分類為1之機率\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xaIMKcRgbLFL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import losses, metrics, optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=['binary_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_9y7lJvbLB6",
        "outputId": "d74fcc44-7f07-4837-8142-36c037760d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 3s 165ms/step - loss: 0.6875 - binary_accuracy: 0.6189 - val_loss: 0.6748 - val_binary_accuracy: 0.6872\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 3s 206ms/step - loss: 0.6601 - binary_accuracy: 0.7467 - val_loss: 0.6486 - val_binary_accuracy: 0.7756\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 3s 199ms/step - loss: 0.6253 - binary_accuracy: 0.7932 - val_loss: 0.6195 - val_binary_accuracy: 0.8039\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 2s 110ms/step - loss: 0.5857 - binary_accuracy: 0.8365 - val_loss: 0.5874 - val_binary_accuracy: 0.8206\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 2s 112ms/step - loss: 0.5435 - binary_accuracy: 0.8604 - val_loss: 0.5529 - val_binary_accuracy: 0.8378\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 2s 117ms/step - loss: 0.4944 - binary_accuracy: 0.8849 - val_loss: 0.5169 - val_binary_accuracy: 0.8450\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 2s 117ms/step - loss: 0.4507 - binary_accuracy: 0.8964 - val_loss: 0.4830 - val_binary_accuracy: 0.8556\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 0.4125 - binary_accuracy: 0.9097 - val_loss: 0.4531 - val_binary_accuracy: 0.8594\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.3682 - binary_accuracy: 0.9190 - val_loss: 0.4235 - val_binary_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 2s 165ms/step - loss: 0.3289 - binary_accuracy: 0.9321 - val_loss: 0.4014 - val_binary_accuracy: 0.8672\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=512,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYw8O7cMbK_C",
        "outputId": "2503622f-3c25-4e84-fdf1-add7aa6a2513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 5ms/step - loss: 0.3930 - binary_accuracy: 0.8720\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3930196166038513, 0.871999979019165]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMoOFkMpBZPY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
